---
title: "NRSG 741 Homework 6"
author: "Tommy FLynn"
date: "April 8th, 2018"
output:
  pdf_document: default
  html_document: default
---


GitHub Repository: [https://github.com/tommyflynn/N741_Homework/tree/master/Flynn_HW_06](https://github.com/tommyflynn/N741_Homework/tree/master/Flynn_HW_06)


```{r setup, include=FALSE, warning=FALSE, message=FALSE}
library(purrr)
library(haven)
library(tidyverse)
library(knitr)
library(stargazer)
library(car)
knitr::opts_chunk$set(echo = FALSE)
```

For homework 6, we use the **HELP** (Health Evaluation and Linkage to Primary Care) Dataset.


### Table 1: Variable Labels for Homework 6, and Table 2: First 6 Observations ###
_Only on the following variables from the HELP dataset are used for this assignment:_

```{r, echo=FALSE, message=FALSE, warning=FALSE}
#load SPSS (.sav) into data.frame helpdata
helpdata <- haven::read_spss("helpmkh.sav")
#subset variables of interest in data.fram h1
# add dichotomous variable to indicate depression for people with CESD scores >= 16 (depressed)
# change cesd_gte16 from LOGIC(boolean) variable type to numeric coded 1=TRUE and 0=FALSE
h1 <- helpdata %>%
  select(age, female, pss_fr, homeless, 
         pcs, mcs, cesd) %>%
  mutate(cesd_gte16 = as.numeric(cesd >=16))
#summary(h1)
# create a function to pull variable names & labels from h1, use attributes()
getlabel <- function(x) attributes(x)$label #I don't really get this part...

#create df without cesd_gte16 for tibble
h2 <- h1 %>%
  select(age, female, pss_fr, homeless, pcs, mcs, cesd)
#create tibble ldf using getlabel() on h1
ldf <- purrr::map_df(h2, getlabel)
#"t(ldf)" will transpose the tibble for easier reading to a single column list

# check final data subset h1 using knitr to get a table of variables with labels
knitr::kable(t(ldf), col.names = c("Variable Label"), caption="Use these variables from HELP dataset for Homework 06")

kable(head(h1), caption="First six rows of the new HELP subset")


```


###1. [Model 1] Run a simple linear regression (`lm()`) for `cesd` using the `mcs` variable, which is the mental component quality of life score from the SF36.  

__Anser:__  
```{r answer 1, echo=FALSE}
plot(cesd ~ mcs, data=h1)
abline(a=53.902, b=-0.665)
reg1 <- lm(cesd ~ mcs, data = h1)
summary(reg1)
```


###2. Write the equation of the final fitted model (i.e. what is the intercept and the slope)? Write a sentence describing the model results (interpret the intercept and slope).  

__Anser:__ _For each unit increase in `mcs`, the `cesd` score decreases by 0.665 units._  
 $cesd = 53.902 - (0.665)mcs$

###3. How much variability in the `cesd` does the `mcs` explain? (what is the $R^2$?) Write a sentence describing how well the `mcs` does in predicting the `cesd`.

__Answer:__ _47% of the variability in `cesd` is explained by `mcs`_ ($R^2=0.47$).


###4. [Model 2] Run a second linear regression model (`lm()`) for the `cesd` putting in all of the other variables:  
```{r answer 4, echo=TRUE}
#Use lm() to regress all variables on cesd
model1 <- lm(cesd ~ age + female + pss_fr + homeless + pcs + mcs, data=h1)
#Print out the model results with the coefficients and tests and model fit statistics.
#summary(model1)
model2 <- lm(cesd ~ female + pss_fr + pcs + mcs, data=h1)
#summary(model2)
stargazer(model1, model2, title="Comparison of 2 Regression Outputs",
           type = "text", align=TRUE)
```

###5. Which variables are significant in the model? Write a sentence or two describing the impact of these variables for predicting depression scores (HINT: interpret the coefficient terms).

__Answer:__  `Female`, `pss_fr`, `pcs` _and_ `mcs` _are all significantly associated with_ `cesd`. _Based on the model with only significant predictors, on average women score higher on the_ `cesd` _by 2.29 points, every unit increase on the physical composite score decreases the_ `cesd` _score by 0.24, a unit increase on the mental composite score decreases_ `cesd` _by 0.62 unites, and 1 unit increase on the social support scale decreases_ `cesd` _by 0.27 units. Overall, this model accounts fo 52% of the variability in_ `cesd` ($R^2=0.52, p=<0.001$).

###6. Following the example we did in class for the Prestige dataset [https://cdn.rawgit.com/vhertzb/2018week9/2f2ea142/2018week9.html?raw=true](https://cdn.rawgit.com/vhertzb/2018week9/2f2ea142/2018week9.html?raw=true), generate the diagnostic plotss for this model with these 6 predictors (e.g. get the residual plot by variables, the added-variable plots, the Q-Q plot, diagnostic plots). Also run the VIFs to check for multicollinearity issues.
```{r task 6, echo=TRUE}
residualPlots(model2)
#lot(resid ~ age + female + pss_fr + homeless + pcs + mcs, data=h1)


```

###7. [Model 3] Repeat Model 1 above, except this time run a logistic regression (`glm()`) to predict CESD scores => 16 (using the `cesd_gte16` as the outcome) as a function of `mcs` scores. Show a summary of the final fitted model and explain the coefficients. [**REMEMBER** to compute the Odds Ratios after you get the raw coefficient (betas)].

###8. Use the `predict()` function like we did in class to predict CESD => 16 and compare it back to the original data. For now, use a cutoff probability of 0.5 - if the probability is > 0.5 consider this to be true and false otherwise. Like we did in class. **REMEMBER** See the R code for the class example at [https://github.com/melindahiggins2000/N741_lecture11_27March2018/blob/master/lesson11_logreg_Rcode.R](https://github.com/melindahiggins2000/N741_lecture11_27March2018/blob/master/lesson11_logreg_Rcode.R)
    + How well did the model correctly predict CESD scores => 16 (indicating depression)? (make the "confusion matrix" and look at the true positives and true negatives versus the false positives and false negatives).
    
###9. Make an ROC curve plot and compute the AUC and explain if this is a good model for predicting depression or not

###10. Make a plot showing the probability curve - put the `mcs` values on the X-axis and the probability of depression on the Y-axis. Based on this plot, do you think the `mcs` is a good predictor of depression? [**FYI** This plot is also called an "effect plot" is you're using `Rcmdr` to do these analyses.]

---