---
title: "NRSG 741 Homework 6"
author: "TommY FLynn"
date: "April 8^th, 2018"
output:
  pdf_document: default
  html_document: default
abstract: |
  Homework 6 was due on 04/06/2018, the same day as my F-31 NRSA application. I wasn't able to complete both. My apologies for being late on this assignment. I wanted to get it done anyway, so I don't get behind. Thanks.
---

_Find the associated GitHub Repository Here: [https://github.com/tommyflynn/N741_Homework/tree/master/Flynn_HW_06](https://github.com/tommyflynn/N741_Homework/tree/master/Flynn_HW_06)_


```{r setup, include=FALSE, warning=FALSE, message=FALSE}
library(purrr)
library(haven)
library(tidyverse)
library(knitr)
knitr::opts_chunk$set(echo = TRUE)
```

For homework 6, we use the **HELP** (Health Evaluation and Linkage to Primary Care) Dataset.


### Variables for Homework 6

Only on the following variables from the HELP dataset are used for this assignment:

```{r, echo=FALSE, message=FALSE, warning=FALSE}
#load SPSS (.sav) into data.frame helpdata
helpdata <- haven::read_spss("helpmkh.sav")
#subset variables of interest in data.fram h1
# add dichotomous variable to indicate depression for people with CESD scores >= 16 (depressed)
# change cesd_gte16 from LOGIC(boolean) variable type to numeric coded 1=TRUE and 0=FALSE
h1 <- helpdata %>%
  select(age, female, pss_fr, homeless, 
         pcs, mcs, cesd) %>%
  mutate(cesd_gte16 = as.numeric(cesd >=16))
#summary(h1)
# create a function to pull variable names & labels from h1, use attributes()
getlabel <- function(x) attributes(x)$label #I don't really get this part... revisit*********

#create df without cesd_gte16 for tibble
h2 <- h1 %>%
  select(age, female, pss_fr, homeless, pcs, mcs, cesd)
#create tibble ldf using getlabel() on h1
ldf <- purrr::map_df(h2, getlabel)
#"t(ldf)" will transpose the tibble for easier reading to a single column list

# check final data subset h1 using knitr to get a table of variables with labels
knitr::kable(t(ldf), col.names = c("Variable Label"), caption="Use these variables from HELP dataset for Homework 06")


kable(head(h1), caption="First six rows of the new HELP subset")


```

## Homework 6 Assignment


For Homework 6, you will be looking at depression in these subjects. First, you will be running a model to look at the continuous depression measure - the CESD [Center for Epidemiologic Studies Depression Scale](http://cesd-r.com/) which is a measure of depressive symptoms. Also see the APA details on the CESD at [http://www.apa.org/pi/about/publications/caregivers/practice-settings/assessment/tools/depression-scale.aspx](http://www.apa.org/pi/about/publications/caregivers/practice-settings/assessment/tools/depression-scale.aspx). The CESD can be used to predict actual clinical depression but it is not technically a diagnosis of depression. The CESD scores range from 0 (no depressive symptoms) to 60 (most severe depressive symptoms). You will use the (`cesd`) variable to run a linear regression.

The recommended threshold used to indicate potential clinical depression is for people with scores of 16 or greater. You will then use the variable created using this cutoff (`cesd_gte16`) to perform a similar modeling approach with the variables to predict the probability of clinical depression (using logistic regression).



###1. [Model 1] Run a simple linear regression (`lm()`) for `cesd` using the `mcs` variable, which is the mental component quality of life score from the SF36.
```{r answer 1, echo=TRUE}
reg1 <- lm(cesd ~ mcs, data = h1)
summary(reg1)
plot(cesd ~ mcs, data=h1)
abline(a=53.902, b=-0.665)
```



###2. Write the equation of the final fitted model (i.e. what is the intercept and the slope)? Write a sentence describing the model results (interpret the intercept and slope). 

\begin{equation}
  cesd = 53.902 - (0.665)mcs
\end{equation}
__For each unit increase in `mcs`, the `cesd` score decreases by 0.665 units.__


###3. How much variability in the `cesd` does the `mcs` explain? (what is the R<sup>2</sup>?) Write a sentence describing how well the `mcs` does in predicting the `cesd`.

__46% of the variability in `cesd` is due to `mcs` (R<sup>2</sup>=0.47).__


###4. [Model 2] Run a second linear regression model (`lm()`) for the `cesd` putting in all of the other variables:
```{r answer 4, echo=TRUE}
model1 <- lm(cesd ~ age + female + pss_fr + homeless + pcs + mcs, data=h1)
    
#Print out the model results with the coefficients and tests and model fit statistics.
summary(model1)
```

###5. Which variables are significant in the model? Write a sentence or two describing the impact of these variables for predicting depression scores (HINT: interpret the coefficient terms).

__`Female, pss_fr, pcs` and `mcs` are all significantly associated with `cesd`. On average, women score higher on the `cesd` by 2.34 points, every unit increase on the physical composite score decreases the `cesd` score by 0.24, a unit increase on the mental composite score decreases `cesd` by 0.62 unites, and 1 unit increase on the social support scale decreased `cesd` by 0.26 units.__

###6. Following the example we did in class for the Prestige dataset [https://cdn.rawgit.com/vhertzb/2018week9/2f2ea142/2018week9.html?raw=true](https://cdn.rawgit.com/vhertzb/2018week9/2f2ea142/2018week9.html?raw=true), generate the diagnostic plotss for this model with these 6 predictors (e.g. get the residual plot by variables, the added-variable plots, the Q-Q plot, diagnostic plots). Also run the VIFs to check for multicollinearity issues.

###7. [Model 3] Repeat Model 1 above, except this time run a logistic regression (`glm()`) to predict CESD scores => 16 (using the `cesd_gte16` as the outcome) as a function of `mcs` scores. Show a summary of the final fitted model and explain the coefficients. [**REMEMBER** to compute the Odds Ratios after you get the raw coefficient (betas)].

###8. Use the `predict()` function like we did in class to predict CESD => 16 and compare it back to the original data. For now, use a cutoff probability of 0.5 - if the probability is > 0.5 consider this to be true and false otherwise. Like we did in class. **REMEMBER** See the R code for the class example at [https://github.com/melindahiggins2000/N741_lecture11_27March2018/blob/master/lesson11_logreg_Rcode.R](https://github.com/melindahiggins2000/N741_lecture11_27March2018/blob/master/lesson11_logreg_Rcode.R)
    + How well did the model correctly predict CESD scores => 16 (indicating depression)? (make the "confusion matrix" and look at the true positives and true negatives versus the false positives and false negatives).
    
###9. Make an ROC curve plot and compute the AUC and explain if this is a good model for predicting depression or not

###10. Make a plot showing the probability curve - put the `mcs` values on the X-axis and the probability of depression on the Y-axis. Based on this plot, do you think the `mcs` is a good predictor of depression? [**FYI** This plot is also called an "effect plot" is you're using `Rcmdr` to do these analyses.]

---